{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Automated Resume Skills Parser Project**\n",
        "\n",
        "In this project, I will demonstrate my knowledge of Natural Processing Language Processing (NLP) in the most simplistic way to help HR and even candidates easily match their skills to the job desription given.\n",
        "\n",
        "This project is very simple and can be used where the resumes are not many.\n"
      ],
      "metadata": {
        "id": "BsDJQgsTE4d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "fp_fCpyqyX68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**import spacy** → Loads spaCy, a powerful NLP library for text processing.\n",
        "\n",
        "**from sklearn.feature_extraction.text import TfidfVectorizer** → Imports TF-IDF vectorizer, which converts text into numerical vectors based on term frequency.\n",
        "\n",
        "**from sklearn.metrics.pairwise import cosine_similarity** → Imports cosine similarity, which measures how similar two text vectors are."
      ],
      "metadata": {
        "id": "KeurCAFAHIt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load spaCy's NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "ndmHN63ZG-01"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads the pre-trained English NLP model (en_core_web_sm), which helps extract information from text"
      ],
      "metadata": {
        "id": "AoUfJ20_He6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create sample resume data (Dictionary Format)\n",
        "resume_data = {\n",
        "    \"Victoria\": \"Victoria is a data scientist expertise in Python, SQL, Excel, and Machine Learning.\",\n",
        "    \"Dora\": \"Dora is a software engineer who specializes in Java, JavaScript, and cloud computing.\",\n",
        "    \"Mary\": \"Mary business analyst is skilled in data visualization, Power BI, and Excel.\",\n",
        "    \"Carl\": \"Carl is a data analyst with expertise in SQL, Python, PowerBI, and Excel\"\n",
        "}"
      ],
      "metadata": {
        "id": "1_j5IEVXG_Fl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dictionary represents sample resumes, where:\n",
        "\n",
        "**Keys (Victoria, Dora, Mary)** → Represent candidates.\n",
        "\n",
        "**Values (resume text):** → Describe each candidate’s skills.:\n",
        "\n",
        "In practice, these resumes would be extracted from PDF or text files. But for the sake of simplicity, we will manually extract the skills."
      ],
      "metadata": {
        "id": "dWETbYXgImDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets define a job description for comparison to the candidate's skills\n",
        "job_description = \"We are looking for a data scientist with experience in Python, Machine Learning, and SQL.\""
      ],
      "metadata": {
        "id": "8k8qUoTyJPGM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This job description contains required skills that will be compared to resumes."
      ],
      "metadata": {
        "id": "sVA93aC2JnK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function that will extract the keywords using spaCy\n",
        "def extract_keywords(text):\n",
        "    doc = nlp(text)  # Process text using spaCy\n",
        "    keywords = [token.text for token in doc if token.pos_ in [\"NOUN\", \"PROPN\"]]\n",
        "    return \" \".join(keywords)"
      ],
      "metadata": {
        "id": "KO_7YS4bJiTJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code processes text using spaCy to extract keywords (skills, job roles), extracts nouns (NOUN) and proper nouns (PROPN), which typically represent important concepts (e.g., Python, SQL, Machine Learning), and finally\n",
        "returns keywords as a string."
      ],
      "metadata": {
        "id": "rgMq4ky7KYh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract keywords from resumes & job description\n",
        "resume_keywords = {name: extract_keywords(text) for name, text in resume_data.items()}\n",
        "job_keywords = extract_keywords(job_description)"
      ],
      "metadata": {
        "id": "qe-21wtEJibX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code does the following:\n",
        "1. Extracts keywords from each resume and stores them in a dictionary.\n",
        "2. Extracts keywords from the job description."
      ],
      "metadata": {
        "id": "41J1hfQ1L157"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert text into numerical vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(list(resume_keywords.values()) + [job_keywords])"
      ],
      "metadata": {
        "id": "frmnQX70JikA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (TfidfVectorizer) converts text into numerical vectors based on:\n",
        "\n",
        "Term Frequency (TF): How often a word appears in the text.\n",
        "\n",
        "Inverse Document Frequency (IDF): How unique the word is across documents.\n",
        "\n",
        "Vectorizes the extracted keywords from resumes and the job description.\n"
      ],
      "metadata": {
        "id": "5CsokqD0MwXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Similarity Scores Using Cosine Similarity\n",
        "similarity_scores = cosine_similarity(vectors[:-1], vectors[-1:]).flatten()"
      ],
      "metadata": {
        "id": "1LVjHwUvNBky"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code computes similarity scores between:\n",
        "\n",
        "Each resume's vector (vectors[:-1])\n",
        "\n",
        "Job description's vector (vectors[-1:])\n",
        "\n",
        "Cosine Similarity measures how similar two text vectors are (values range from 0 to 1, where 1 = perfect match)."
      ],
      "metadata": {
        "id": "op1zzUfmtkyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rank resumes based on similarity scores\n",
        "ranked_resumes = sorted(zip(resume_data.keys(), similarity_scores), key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "id": "ffEUNti5wgs3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairs resume names with similarity scores, and sorts resumes in descending order (best match first)"
      ],
      "metadata": {
        "id": "fhywfZXZw9ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display the ranked resumes\n",
        "print(\"Ranked Resumes:\")\n",
        "for name, score in ranked_resumes:\n",
        "    print(f\"{name}: {score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQsAvTpOxBk-",
        "outputId": "ef6d96f3-c1fa-4db7-ebdf-81f5dd9d9f2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Resumes:\n",
            "Victoria: 0.68\n",
            "Carl: 0.27\n",
            "Mary: 0.06\n",
            "Dora: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Victoria is the best match for the Data Scientist role since her skills align the most."
      ],
      "metadata": {
        "id": "IT1GOpe_z3yx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HgQ8gyu-0CZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "This is a beginner friendly project to help grasp the idea behind how spacy library works in helping to sort out text, match and score them according to the need.\n",
        "\n",
        "**Extensions for More Impact**\n",
        "\n",
        "In this project, I have explored a basic resume skills match program which extracts keywords and match with job descriptions.\n",
        "\n",
        "Going forward, I will take it up a notch by adding a streamlit web app for recruiters to upload resumes."
      ],
      "metadata": {
        "id": "sMfGICSt0C0x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7tsVJ-gKL4y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}